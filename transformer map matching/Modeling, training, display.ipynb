{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9176657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Ipynb_importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3062095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture #忽略输出\n",
    "import s07_训练数据生成 as datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51b0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d276548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "edges, nodes = datagen.load_data(\"edgeOSM.txt\",\"nodeOSM.txt\")\n",
    "G = datagen.create_networkx_graph(edges, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641de5f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRAJ_MAX_LENGTH = 126  # 输入最长128 要给前后缀留下位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9251e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "边总量： 4504\n"
     ]
    }
   ],
   "source": [
    "print(\"边总量：\",len(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45abc70b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "距离： 904.8232147463399\n",
      "坐标点个数： 41\n",
      "采样后个数： 24\n",
      "[3953, 3953, 3955, 3134, 1767, 3132, 3957, 3130, 3959, 2354, 1771, 3961, 3961, 1678, 3128, 3963, 3965, 3124, 1617, 3126, 3967, 3120, 1619, 3118, 3969, 1621, 3433, 3116, 1634, 1642, 3115, 1647, 3114, 1650, 1656, 1625, 1623, 1671, 1648, 2356, 2357]\n",
      "[3134, 1767, 3132, 3957, 1771, 3961, 3128, 3963, 3965, 3124, 3126, 3120, 3118, 3969, 1621, 3433, 3116, 1634, 1642, 3115, 3114, 1656, 1671, 2357]\n",
      "[[40.5637929, -3.4932821], [40.563762, -3.4933658], [40.5637435, -3.4934599], [40.5637395, -3.4935679], [40.563933, -3.4943782], [40.5642965, -3.49532895], [40.5649064, -3.4969468], [40.5649295, -3.4970793], [40.5649474, -3.4972168], [40.5649496, -3.4973691], [40.564897, -3.4980827], [40.5649122, -3.4983829], [40.5650484, -3.499265], [40.5651363, -3.4995969], [40.5653204, -3.5002325], [40.5653797, -3.5003264], [40.5654663, -3.5005335], [40.5655311, -3.5006659], [40.565656, -3.500824], [40.5657922, -3.5009859], [40.565879, -3.5011519], [40.5657948, -3.501223], [40.5656246, -3.5009502], [40.5653434, -3.5003491]]\n",
      "[[40.56349534103095, -3.4930727326642006], [40.5641564638411, -3.4933221950655025], [40.563783229554794, -3.493325728831221], [40.5634439148954, -3.493371031120308], [40.563743660120174, -3.4941574269059217], [40.56444525143661, -3.4954922488955256], [40.565043172179735, -3.496981005364442], [40.5650403882526, -3.4971267964203876], [40.56488536302698, -3.4972478004892644], [40.56462628619276, -3.4972118439219977], [40.564993741968564, -3.498094772754078], [40.564974914937686, -3.4984523392169016], [40.56483803446585, -3.4990479835147226], [40.56505264691206, -3.4997949207217163], [40.56505711885661, -3.5002319120677825], [40.56544445935347, -3.5002712060605865], [40.56545994963163, -3.50045787275409], [40.56529617702792, -3.500445061990657], [40.56541707332733, -3.500873432118908], [40.56569966588786, -3.501229539930009], [40.56582381592874, -3.5008702755236327], [40.56571815080401, -3.5011770420216535], [40.56548239868486, -3.500866040811209], [40.56522682584464, -3.5002824172854123]]\n"
     ]
    }
   ],
   "source": [
    "path = datagen.generate_path(G)  # 路径\n",
    "traj, coord, dis = datagen.generate_traj(G, path) # 详细轨迹\n",
    "sampled_traj, sampled_coord = datagen.sample_lists(traj, coord, min(TRAJ_MAX_LENGTH,int(len(traj)*0.6))) #采样\n",
    "noisy_coord = [datagen.add_gaussian_noise(c, np.random.randint(10, 25)) for c in sampled_coord]  #加噪\n",
    "\n",
    "print('距离：',dis)\n",
    "print('坐标点个数：',len(traj))\n",
    "print(\"采样后个数：\",len(sampled_traj))\n",
    "\n",
    "import json\n",
    "print(json.dumps(traj))\n",
    "print(json.dumps(sampled_traj))\n",
    "print(json.dumps(sampled_coord))\n",
    "print(json.dumps(noisy_coord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a853781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_traj(G):\n",
    "    \"\"\"\n",
    "    This function takes a networkx graph 'G' as input and generates a noisy trajectory.\n",
    "    \"\"\"\n",
    "    path = datagen.generate_path(G)\n",
    "    traj, coord, dis = datagen.generate_traj(G, path)\n",
    "    sampled_traj, sampled_coord = datagen.sample_lists(traj, coord, min(TRAJ_MAX_LENGTH,int(len(traj)*0.6)))\n",
    "    noisy_coord = [datagen.add_gaussian_noise(c, np.random.randint(10, 25)) for c in sampled_coord]\n",
    "    return sampled_traj, noisy_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e80d6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC ->  [[40.5524584201445, -3.495878735791361], [40.55252185259225, -3.496087745054628], [40.552938008049686, -3.4961936433709764], [40.552998967116196, -3.4958868029113965], [40.55265195373048, -3.4960654820215353], [40.55261424440494, -3.496138156253101]]\n",
      "TGT ->  [1174, 2045, 1175, 1177, 1181, 264]\n"
     ]
    }
   ],
   "source": [
    "traj,coords = generate_noisy_traj(G)\n",
    "\n",
    "print('SRC -> ',json.dumps(coords))\n",
    "print('TGT -> ',json.dumps(traj))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac8678d",
   "metadata": {},
   "source": [
    "# 转换为词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96c6974d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTM X 坐标为： 500000.0\n",
      "UTM Y 坐标为： 4483254.73193229\n",
      "所在UTM投影区域为： 30 T\n"
     ]
    }
   ],
   "source": [
    "import utm\n",
    "\n",
    "# 经纬度坐标\n",
    "lon, lat = -3, 40.5\n",
    "\n",
    "# 将经纬度坐标转换为UTM坐标\n",
    "x, y, zone_num, zone_letter = utm.from_latlon(lat, lon)\n",
    "\n",
    "# 输出UTM坐标\n",
    "print(\"UTM X 坐标为：\", x)\n",
    "print(\"UTM Y 坐标为：\", y)\n",
    "print(\"所在UTM投影区域为：\", zone_num, zone_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c69433b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>zone_num</th>\n",
       "      <th>zone_letter</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40.583622</td>\n",
       "      <td>-3.566653</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>452044.820109</td>\n",
       "      <td>4.492691e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>40.583762</td>\n",
       "      <td>-3.566087</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>452092.888399</td>\n",
       "      <td>4.492706e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>40.583886</td>\n",
       "      <td>-3.565532</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>452139.945821</td>\n",
       "      <td>4.492720e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>40.583988</td>\n",
       "      <td>-3.565037</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>452181.883934</td>\n",
       "      <td>4.492731e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>40.584462</td>\n",
       "      <td>-3.559403</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>452659.024998</td>\n",
       "      <td>4.492780e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>2913</td>\n",
       "      <td>40.554195</td>\n",
       "      <td>-3.495452</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>458052.187436</td>\n",
       "      <td>4.489388e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>2914</td>\n",
       "      <td>40.554255</td>\n",
       "      <td>-3.495139</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>458078.699830</td>\n",
       "      <td>4.489395e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>2915</td>\n",
       "      <td>40.554262</td>\n",
       "      <td>-3.494986</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>458091.691655</td>\n",
       "      <td>4.489395e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>2916</td>\n",
       "      <td>40.553634</td>\n",
       "      <td>-3.494254</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>458153.217018</td>\n",
       "      <td>4.489325e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>2917</td>\n",
       "      <td>40.553219</td>\n",
       "      <td>-3.494622</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>458121.818311</td>\n",
       "      <td>4.489280e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2918 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       nid        lat       lon  zone_num zone_letter              x   \n",
       "0        0  40.583622 -3.566653        30           T  452044.820109  \\\n",
       "1        1  40.583762 -3.566087        30           T  452092.888399   \n",
       "2        2  40.583886 -3.565532        30           T  452139.945821   \n",
       "3        3  40.583988 -3.565037        30           T  452181.883934   \n",
       "4        4  40.584462 -3.559403        30           T  452659.024998   \n",
       "...    ...        ...       ...       ...         ...            ...   \n",
       "2913  2913  40.554195 -3.495452        30           T  458052.187436   \n",
       "2914  2914  40.554255 -3.495139        30           T  458078.699830   \n",
       "2915  2915  40.554262 -3.494986        30           T  458091.691655   \n",
       "2916  2916  40.553634 -3.494254        30           T  458153.217018   \n",
       "2917  2917  40.553219 -3.494622        30           T  458121.818311   \n",
       "\n",
       "                 y  \n",
       "0     4.492691e+06  \n",
       "1     4.492706e+06  \n",
       "2     4.492720e+06  \n",
       "3     4.492731e+06  \n",
       "4     4.492780e+06  \n",
       "...            ...  \n",
       "2913  4.489388e+06  \n",
       "2914  4.489395e+06  \n",
       "2915  4.489395e+06  \n",
       "2916  4.489325e+06  \n",
       "2917  4.489280e+06  \n",
       "\n",
       "[2918 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 定义转换函数\n",
    "def convert_to_utm(row):\n",
    "    lon, lat = row['lon'], row['lat']\n",
    "    x, y, zone_num, zone_letter = utm.from_latlon(lat, lon)\n",
    "    return pd.Series({'zone_num': zone_num, 'zone_letter': zone_letter,'x': x, 'y': y})\n",
    "\n",
    "# 对每行数据进行转换\n",
    "nodes[[ 'zone_num', 'zone_letter','x', 'y']] = nodes.apply(convert_to_utm, axis=1)\n",
    "\n",
    "# 输出结果\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4071eabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>zone_num</th>\n",
       "      <th>zone_letter</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x_new</th>\n",
       "      <th>y_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40.583622</td>\n",
       "      <td>-3.566653</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>452044.820109</td>\n",
       "      <td>4.492691e+06</td>\n",
       "      <td>4520</td>\n",
       "      <td>44926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>40.583762</td>\n",
       "      <td>-3.566087</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>452092.888399</td>\n",
       "      <td>4.492706e+06</td>\n",
       "      <td>4520</td>\n",
       "      <td>44927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>40.583886</td>\n",
       "      <td>-3.565532</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>452139.945821</td>\n",
       "      <td>4.492720e+06</td>\n",
       "      <td>4521</td>\n",
       "      <td>44927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>40.583988</td>\n",
       "      <td>-3.565037</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>452181.883934</td>\n",
       "      <td>4.492731e+06</td>\n",
       "      <td>4521</td>\n",
       "      <td>44927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>40.584462</td>\n",
       "      <td>-3.559403</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>452659.024998</td>\n",
       "      <td>4.492780e+06</td>\n",
       "      <td>4526</td>\n",
       "      <td>44927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>2913</td>\n",
       "      <td>40.554195</td>\n",
       "      <td>-3.495452</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>458052.187436</td>\n",
       "      <td>4.489388e+06</td>\n",
       "      <td>4580</td>\n",
       "      <td>44893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>2914</td>\n",
       "      <td>40.554255</td>\n",
       "      <td>-3.495139</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>458078.699830</td>\n",
       "      <td>4.489395e+06</td>\n",
       "      <td>4580</td>\n",
       "      <td>44893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>2915</td>\n",
       "      <td>40.554262</td>\n",
       "      <td>-3.494986</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>458091.691655</td>\n",
       "      <td>4.489395e+06</td>\n",
       "      <td>4580</td>\n",
       "      <td>44893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>2916</td>\n",
       "      <td>40.553634</td>\n",
       "      <td>-3.494254</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>458153.217018</td>\n",
       "      <td>4.489325e+06</td>\n",
       "      <td>4581</td>\n",
       "      <td>44893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>2917</td>\n",
       "      <td>40.553219</td>\n",
       "      <td>-3.494622</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>458121.818311</td>\n",
       "      <td>4.489280e+06</td>\n",
       "      <td>4581</td>\n",
       "      <td>44892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2918 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       nid        lat       lon  zone_num zone_letter              x   \n",
       "0        0  40.583622 -3.566653        30           T  452044.820109  \\\n",
       "1        1  40.583762 -3.566087        30           T  452092.888399   \n",
       "2        2  40.583886 -3.565532        30           T  452139.945821   \n",
       "3        3  40.583988 -3.565037        30           T  452181.883934   \n",
       "4        4  40.584462 -3.559403        30           T  452659.024998   \n",
       "...    ...        ...       ...       ...         ...            ...   \n",
       "2913  2913  40.554195 -3.495452        30           T  458052.187436   \n",
       "2914  2914  40.554255 -3.495139        30           T  458078.699830   \n",
       "2915  2915  40.554262 -3.494986        30           T  458091.691655   \n",
       "2916  2916  40.553634 -3.494254        30           T  458153.217018   \n",
       "2917  2917  40.553219 -3.494622        30           T  458121.818311   \n",
       "\n",
       "                 y  x_new  y_new  \n",
       "0     4.492691e+06   4520  44926  \n",
       "1     4.492706e+06   4520  44927  \n",
       "2     4.492720e+06   4521  44927  \n",
       "3     4.492731e+06   4521  44927  \n",
       "4     4.492780e+06   4526  44927  \n",
       "...            ...    ...    ...  \n",
       "2913  4.489388e+06   4580  44893  \n",
       "2914  4.489395e+06   4580  44893  \n",
       "2915  4.489395e+06   4580  44893  \n",
       "2916  4.489325e+06   4581  44893  \n",
       "2917  4.489280e+06   4581  44892  \n",
       "\n",
       "[2918 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes['x_new'] = (nodes['x'] // 100).astype(int)#将区域划分为100米*100米方格并编号，这里是格子的数量\n",
    "nodes['y_new'] = (nodes['y'] // 100).astype(int)\n",
    "\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8aa313e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>zone_num</th>\n",
       "      <th>zone_letter</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x_new</th>\n",
       "      <th>y_new</th>\n",
       "      <th>new_field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40.583622</td>\n",
       "      <td>-3.566653</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>452044.820109</td>\n",
       "      <td>4.492691e+06</td>\n",
       "      <td>4520</td>\n",
       "      <td>44926</td>\n",
       "      <td>30T 4520 44926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>40.583762</td>\n",
       "      <td>-3.566087</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>452092.888399</td>\n",
       "      <td>4.492706e+06</td>\n",
       "      <td>4520</td>\n",
       "      <td>44927</td>\n",
       "      <td>30T 4520 44927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>40.583886</td>\n",
       "      <td>-3.565532</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>452139.945821</td>\n",
       "      <td>4.492720e+06</td>\n",
       "      <td>4521</td>\n",
       "      <td>44927</td>\n",
       "      <td>30T 4521 44927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>40.583988</td>\n",
       "      <td>-3.565037</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>452181.883934</td>\n",
       "      <td>4.492731e+06</td>\n",
       "      <td>4521</td>\n",
       "      <td>44927</td>\n",
       "      <td>30T 4521 44927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>40.584462</td>\n",
       "      <td>-3.559403</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>452659.024998</td>\n",
       "      <td>4.492780e+06</td>\n",
       "      <td>4526</td>\n",
       "      <td>44927</td>\n",
       "      <td>30T 4526 44927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>2913</td>\n",
       "      <td>40.554195</td>\n",
       "      <td>-3.495452</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>458052.187436</td>\n",
       "      <td>4.489388e+06</td>\n",
       "      <td>4580</td>\n",
       "      <td>44893</td>\n",
       "      <td>30T 4580 44893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>2914</td>\n",
       "      <td>40.554255</td>\n",
       "      <td>-3.495139</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>458078.699830</td>\n",
       "      <td>4.489395e+06</td>\n",
       "      <td>4580</td>\n",
       "      <td>44893</td>\n",
       "      <td>30T 4580 44893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>2915</td>\n",
       "      <td>40.554262</td>\n",
       "      <td>-3.494986</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>458091.691655</td>\n",
       "      <td>4.489395e+06</td>\n",
       "      <td>4580</td>\n",
       "      <td>44893</td>\n",
       "      <td>30T 4580 44893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>2916</td>\n",
       "      <td>40.553634</td>\n",
       "      <td>-3.494254</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>458153.217018</td>\n",
       "      <td>4.489325e+06</td>\n",
       "      <td>4581</td>\n",
       "      <td>44893</td>\n",
       "      <td>30T 4581 44893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>2917</td>\n",
       "      <td>40.553219</td>\n",
       "      <td>-3.494622</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>458121.818311</td>\n",
       "      <td>4.489280e+06</td>\n",
       "      <td>4581</td>\n",
       "      <td>44892</td>\n",
       "      <td>30T 4581 44892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2918 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       nid        lat       lon  zone_num zone_letter              x   \n",
       "0        0  40.583622 -3.566653        30           T  452044.820109  \\\n",
       "1        1  40.583762 -3.566087        30           T  452092.888399   \n",
       "2        2  40.583886 -3.565532        30           T  452139.945821   \n",
       "3        3  40.583988 -3.565037        30           T  452181.883934   \n",
       "4        4  40.584462 -3.559403        30           T  452659.024998   \n",
       "...    ...        ...       ...       ...         ...            ...   \n",
       "2913  2913  40.554195 -3.495452        30           T  458052.187436   \n",
       "2914  2914  40.554255 -3.495139        30           T  458078.699830   \n",
       "2915  2915  40.554262 -3.494986        30           T  458091.691655   \n",
       "2916  2916  40.553634 -3.494254        30           T  458153.217018   \n",
       "2917  2917  40.553219 -3.494622        30           T  458121.818311   \n",
       "\n",
       "                 y  x_new  y_new       new_field  \n",
       "0     4.492691e+06   4520  44926  30T 4520 44926  \n",
       "1     4.492706e+06   4520  44927  30T 4520 44927  \n",
       "2     4.492720e+06   4521  44927  30T 4521 44927  \n",
       "3     4.492731e+06   4521  44927  30T 4521 44927  \n",
       "4     4.492780e+06   4526  44927  30T 4526 44927  \n",
       "...            ...    ...    ...             ...  \n",
       "2913  4.489388e+06   4580  44893  30T 4580 44893  \n",
       "2914  4.489395e+06   4580  44893  30T 4580 44893  \n",
       "2915  4.489395e+06   4580  44893  30T 4580 44893  \n",
       "2916  4.489325e+06   4581  44893  30T 4581 44893  \n",
       "2917  4.489280e+06   4581  44892  30T 4581 44892  \n",
       "\n",
       "[2918 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes['new_field'] = nodes['zone_num'].astype(str) + nodes['zone_letter'] + ' '+ nodes['x_new'].astype(str) + ' '+  nodes['y_new'].astype(str)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f051440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4662\n",
      "4515\n",
      "44938\n",
      "44847\n"
     ]
    }
   ],
   "source": [
    "print(nodes['x_new'].max()+5)\n",
    "print(nodes['x_new'].min()-5)\n",
    "print(nodes['y_new'].max()+5)\n",
    "print(nodes['y_new'].min()-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "512fd5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NODE Vocab Size:  13381\n",
      "EDGE Vocab Size:  4508\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "\n",
    "def yield_node_tokens():\n",
    "    for x in range(nodes['x_new'].min()-5,nodes['x_new'].max()+5):\n",
    "        for y in range(nodes['y_new'].min()-5,nodes['y_new'].max()+5):\n",
    "            node = \"30T {} {}\".format(x, y)\n",
    "            yield [node]\n",
    "\n",
    "node_vocab = build_vocab_from_iterator(  yield_node_tokens(),\n",
    "                                    min_freq=1,\n",
    "                                    specials=special_symbols,\n",
    "                                    special_first=True)\n",
    "node_vocab.set_default_index(UNK_IDX)\n",
    "\n",
    "print(\"NODE Vocab Size: \", len(node_vocab))\n",
    "# print(\"Vocab Itos: \", node_vocab.get_itos() )\n",
    "# print(\"Vocab Stoi: \", node_vocab.get_stoi() )\n",
    "\n",
    "def yield_edge_tokens():\n",
    "    for eid in edges['eid']:\n",
    "        yield [str(eid)]\n",
    "\n",
    "edge_vocab = build_vocab_from_iterator(  yield_edge_tokens(),\n",
    "                                    min_freq=1,\n",
    "                                    specials=special_symbols,\n",
    "                                    special_first=True)\n",
    "edge_vocab.set_default_index(UNK_IDX)\n",
    "\n",
    "print(\"EDGE Vocab Size: \", len(edge_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dee0833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[538]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_vocab(['30T 4520 44926'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "968fe79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5963, 5873, 5873, 5964, 5873, 5873]\n",
      "[200, 1168, 201, 203, 208, 1828]\n",
      "[1174, 2045, 1175, 1177, 1181, 264]\n",
      "6\n",
      "6\n",
      "['30T 4580 44891', '30T 4579 44892', '30T 4579 44892', '30T 4580 44892', '30T 4579 44892', '30T 4579 44892']\n",
      "['1174', '2045', '1175', '1177', '1181', '264']\n"
     ]
    }
   ],
   "source": [
    "def coord_to_utm_str(coord):\n",
    "    lat = coord[0]\n",
    "    lon = coord[1]\n",
    "    x, y, zone_num, zone_letter = utm.from_latlon(lat, lon)\n",
    "    utm_str = \"{}{} {} {}\".format(zone_num, zone_letter, int(x//100), int(y//100))\n",
    "    return utm_str\n",
    "\n",
    "def coords_to_utm_strs(coords):\n",
    "    return [coord_to_utm_str(coord) for coord in coords]\n",
    "\n",
    "vocab_ids = node_vocab(coords_to_utm_strs(coords))\n",
    "print(vocab_ids)\n",
    "\n",
    "\n",
    "def as_strs(eids):\n",
    "    return [str(eid) for eid in eids]\n",
    "\n",
    "edge_ids = edge_vocab(as_strs(traj))\n",
    "print(edge_ids)\n",
    "print(traj)\n",
    "\n",
    "print(len(vocab_ids))\n",
    "print(len(traj))\n",
    "\n",
    "print(node_vocab.lookup_tokens(vocab_ids))\n",
    "print(edge_vocab.lookup_tokens(edge_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8719633b",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f0299a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "from typing import Iterable, List\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,   #将区域划分为100米*100米方格并编号，这里是格子的数量\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3af82d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c9272f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(node_vocab)#将区域划分为100米*100米方格并编号，这里是格子的数量\n",
    "TGT_VOCAB_SIZE = len(edge_vocab)\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "TRAIN_SAMPLE_SIZE = 150000 # 15万\n",
    "VAL_SAMPLE_SIZE = 256\n",
    "\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b4582b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
    "node_trans = sequential_transforms(coords_to_utm_strs, #Tokenization\n",
    "                                   node_vocab, #Numericalization\n",
    "                                   tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "edge_trans = sequential_transforms(as_strs, #Tokenization\n",
    "                                   edge_vocab, #Numericalization\n",
    "                                   tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(node_trans(src_sample))\n",
    "        tgt_batch.append(edge_trans(tgt_sample))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9a96bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40.54247894388765, -3.5371216711742166], [40.54251460141223, -3.537535505274104], [40.5425513378431, -3.5380132038414582], [40.5425269434341, -3.538101878213174], [40.54331831420923, -3.5382586396102704], [40.543512866580976, -3.5389112126366777], [40.543773856756474, -3.5390785315185624], [40.543675108672744, -3.5395785855074053], [40.54382725780681, -3.540118654376489], [40.543612073865695, -3.5401050750083978], [40.543655704158674, -3.5404157385343287], [40.543467987710955, -3.5406224326035147], [40.54337245244819, -3.540675454682942], [40.54285800857531, -3.5414829787515005], [40.54190527531011, -3.543372876864134], [40.54153843809441, -3.544031175247652], [40.54127333264991, -3.545130695280617], [40.54048878212936, -3.5457305101645122], [40.540086327525366, -3.5462365184258764], [40.53985732740687, -3.5469711566385906], [40.54029694491578, -3.546456333219069], [40.54015219529057, -3.5462268784746516], [40.54150752765223, -3.54353798786314]]\n",
      "[2589, 2589, 291, 2583, 2582, 2580, 2579, 2577, 4098, 2573, 2569, 4094, 4114, 4111, 4115, 4087, 4087, 299, 299, 369, 374, 2667, 377]\n",
      "1120\n",
      "([[40.524296574023744, -3.4167245013799312], [40.52427407007881, -3.415906633685799], [40.523764627321725, -3.4154755089388833], [40.523137884386095, -3.4146275270873785], [40.52221727487116, -3.413786373177879], [40.52158568325458, -3.4125830157396875], [40.52031786283999, -3.4114825534614583], [40.51992181475875, -3.411508031165592], [40.51961869948212, -3.4117295743098026], [40.51941657849727, -3.4125314246323804], [40.519289300931206, -3.4129238761061904], [40.51988222913089, -3.4146857549912277], [40.51998592457892, -3.4151963927407243], [40.52051025338322, -3.4154855988685564], [40.52021221939547, -3.415945599897629], [40.520000388595896, -3.4151438604562108], [40.51982666804611, -3.414823899307293], [40.519444790481465, -3.4141621741595034], [40.51928875971354, -3.413892422649946], [40.51921733583295, -3.4115779756625106], [40.51951348054931, -3.4113326817569196], [40.519260847899254, -3.4109537557767546], [40.51983741369831, -3.410884182097593], [40.519723952325855, -3.410428467142555], [40.519769344380386, -3.4104020914363042], [40.51982995761482, -3.4099694791129918], [40.52001490795051, -3.410311792670702], [40.52031108736719, -3.409965314112064], [40.52013275994797, -3.410137985186004], [40.52080466125182, -3.410338058005311], [40.52055594143526, -3.410023423180617], [40.52072894093032, -3.410146405194458], [40.52084799030956, -3.410362759046542], [40.52074926237717, -3.4102970367293124], [40.5208740081701, -3.4111658756237104], [40.521011190663344, -3.4119700400424047], [40.52115299651202, -3.4119535745299063], [40.521203473637534, -3.412134362946601], [40.52157441260613, -3.4123317909365296], [40.52200642004839, -3.4131008436645325], [40.52399026670389, -3.4153848963435443], [40.5242613703293, -3.415876632779462], [40.52487914987827, -3.416132013702531], [40.52506906447874, -3.4171710826616697], [40.525110770553596, -3.417418282531322], [40.5253292900029, -3.4183983625563887], [40.52550370015648, -3.41888934657939], [40.52594239117539, -3.4196953203386187], [40.52592595569201, -3.420768568871712], [40.526424381924215, -3.420686197366355], [40.52710938455236, -3.4211909009550183], [40.526795016294905, -3.4207961480131344], [40.526556227622414, -3.42110491499397], [40.52627692782809, -3.4210144017281223], [40.52507200512814, -3.420927239081135], [40.52489469044866, -3.420772738269421], [40.524863548962394, -3.4204488975124323], [40.524667827557536, -3.4205144854726264], [40.52441707938395, -3.420231506247691], [40.524331616395024, -3.4199191965813536], [40.524372981439555, -3.419806874293692], [40.52421568366299, -3.4191060374507796], [40.52415564356725, -3.4192167675968377], [40.52444920654861, -3.418520611330673], [40.52433483518483, -3.418413294655705], [40.524520060360544, -3.418154304737343], [40.52448948653648, -3.417872575851193], [40.52460432562209, -3.417818620560466], [40.52476776874941, -3.416988504258643]], [3727, 3727, 3728, 667, 669, 671, 3064, 520, 1480, 525, 1479, 465, 1488, 1489, 1493, 1491, 1485, 339, 339, 342, 1475, 511, 508, 506, 3071, 527, 3066, 504, 1500, 502, 499, 500, 1507, 517, 515, 513, 1516, 512, 659, 4051, 3710, 3709, 3708, 3706, 1527, 3705, 3705, 3704, 3702, 3735, 3713, 1791, 1793, 3741, 3717, 3047, 3048, 3720, 3721, 3052, 3053, 3057, 3723, 3059, 3724, 3060, 3061, 3725, 3726])\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "class NoisyTrajIterator:\n",
    "    def __init__(self, n ,G):\n",
    "        self.n = n  # 要迭代的次数\n",
    "        self.current = 0 # 当前迭代位置\n",
    "        self.G = G\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self  # 返回迭代器对象（self）\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current < self.n:\n",
    "            eids,coords = generate_noisy_traj(self.G)\n",
    "            while len(eids) < 2 :\n",
    "                 eids,coords = generate_noisy_traj(self.G)\n",
    "            self.current += 1  # 定位到下一个元素\n",
    "            return coords, eids\n",
    "        else:\n",
    "            raise StopIteration\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "    \n",
    "    def __getitem__(self, key):  # 每次都是随机，制定索引无效， 这里只是为了配合 DataLoader\n",
    "        return self.__next__()\n",
    "        \n",
    "for n,e in NoisyTrajIterator(1,G):\n",
    "    print(n)\n",
    "    print(e)\n",
    "    \n",
    "print(len(NoisyTrajIterator(1120,G)))\n",
    "\n",
    "print (NoisyTrajIterator(23,G)[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d51918a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    train_iter = NoisyTrajIterator(TRAIN_SAMPLE_SIZE,G)\n",
    "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn, num_workers=NUM_WORKERS )\n",
    "\n",
    "    for src, tgt in tqdm(train_dataloader):\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    # return losses / len(list(train_dataloader))\n",
    "    return losses / math.ceil(TRAIN_SAMPLE_SIZE / BATCH_SIZE)\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    val_iter = NoisyTrajIterator(VAL_SAMPLE_SIZE,G)\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn, num_workers=NUM_WORKERS )\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "        \n",
    "        # 模型保存\n",
    "        checkpoint = {'model_state_dict': transformer.state_dict(),\n",
    "                      'optimizer_state_dict': optimizer.state_dict()}\n",
    "        torch.save(checkpoint, \"./checkpoints/checkpoint_emb_{}_head_{}_ffn_{}_enclayer_{}_declayer_{}_loss_{:.3f}.pth\".format(EMB_SIZE, NHEAD, FFN_HID_DIM,NUM_ENCODER_LAYERS,NUM_DECODER_LAYERS, loss))\n",
    "\n",
    "    #return losses / len(list(val_dataloader))\n",
    "    return losses / math.ceil(VAL_SAMPLE_SIZE / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced8389a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/1172 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 18\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04db8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def map_mapping(model: torch.nn.Module, src_coords: str):\n",
    "    model.eval()\n",
    "    src = node_trans(src_coords).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    predict = edge_vocab.lookup_tokens(list(tgt_tokens.cpu().numpy()))\n",
    "    return [x for x in predict if x != '<bos>' and  x != '<eos>']\n",
    "\n",
    "def show_map_mapping(model: torch.nn.Module, src_coords: str):\n",
    "    return \" \".join(map_mapping(model,src_coords)).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eids,coords = generate_noisy_traj(G)\n",
    "print('PREDICT -> ',show_map_mapping(transformer, coords))\n",
    "print('REAL    ->  ', \" \".join([str(eid) for eid in eids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c4505-1df8-444f-8692-cac70f584189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型保存和加载\n",
    "# loss = 0.726\n",
    "# checkpoint = {'model_state_dict': transformer.state_dict(),\n",
    "#               'optimizer_state_dict': optimizer.state_dict()}\n",
    "# torch.save(checkpoint, \"checkpoint_emb_{}_head_{}_ffn_{}_enclayer_{}_declayer_{}_loss_{:.3f}.pth\".format(EMB_SIZE, NHEAD, FFN_HID_DIM,NUM_ENCODER_LAYERS,NUM_DECODER_LAYERS, loss))\n",
    "# checkpoint = torch.load('model.pth')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20734eba-18d1-4920-8813-d5e1f582cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "eids,coords = generate_noisy_traj(G)\n",
    "predict = map_mapping(transformer, coords)\n",
    "print('PREDICT -> ', predict)\n",
    "print('REAL    -> ', [str(eid) for eid in eids])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b87ef98-550c-44b1-8e63-8b914e769d2d",
   "metadata": {},
   "source": [
    "## 用最短路径填充间隙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce071b56-8060-47a6-adb4-cbd7b4ee7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def gen_full_edges(edge_ids):\n",
    "    full_edges = []\n",
    "\n",
    "    last_end_node_id = None\n",
    "    last_edge_id = None\n",
    "\n",
    "    for eid in edge_ids:\n",
    "        eid = int(eid)\n",
    "        if last_edge_id:\n",
    "            if eid == last_edge_id :\n",
    "                continue\n",
    "        if last_end_node_id:\n",
    "            curr_start_node_id = edges.loc[eid,'start_node']\n",
    "            node_path = nx.shortest_path(G, source=last_end_node_id, target=curr_start_node_id)\n",
    "            if len(node_path) >1 :\n",
    "                for i in range(1,len(node_path)):\n",
    "                    start_node = node_path[i-1]\n",
    "                    end_node = node_path[i]\n",
    "                    edge_gap = edges[edges['start_node']==start_node ][ edges['end_node']==end_node ]['eid'].item()\n",
    "                    full_edges += [edge_gap]\n",
    "        full_edges += [eid]\n",
    "        last_end_node_id = edges.loc[eid,'end_node']\n",
    "        last_edge_id = eid\n",
    "    return full_edges\n",
    "\n",
    "full_predict = gen_full_edges(predict)\n",
    "full_real =gen_full_edges(eids)\n",
    "\n",
    "\n",
    "print(len(full_predict))\n",
    "print(len(full_real))\n",
    "\n",
    "print(json.dumps(full_predict))\n",
    "print(json.dumps(full_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2951f6-a811-4a1b-a741-6229d9ce8424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回最长公共子串\n",
    "def longest_common_substring(A, B):\n",
    "    n, m = len(A), len(B)\n",
    "    L = [[0] * (m+1) for _ in range(n+1)]\n",
    "    max_len, end_pos = 0, -1\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            if A[i-1] != B[j-1]:\n",
    "                L[i][j] = 0\n",
    "            else:\n",
    "                L[i][j] = L[i-1][j-1] + 1\n",
    "                if L[i][j] > max_len:\n",
    "                    max_len = L[i][j]\n",
    "                    end_pos = i-1\n",
    "    \n",
    "    begin_pos = end_pos - max_len + 1\n",
    "    return A[begin_pos:end_pos+1]\n",
    "\n",
    "common = longest_common_substring(full_predict,full_real)\n",
    "\n",
    "print(len(common))\n",
    "\n",
    "print(json.dumps(common))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0903b64e-7ef7-4294-bedf-9fc590d2327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    eids,coords = generate_noisy_traj(G)\n",
    "    while len(eids) < 2 :\n",
    "        eids,coords = generate_noisy_traj(self.G)\n",
    "            \n",
    "    predict = map_mapping(transformer, coords)\n",
    "    print('PREDICT -> ', predict)\n",
    "    print('REAL    -> ', [str(eid) for eid in eids])\n",
    "    \n",
    "    full_predict = gen_full_edges(predict)\n",
    "    full_real =gen_full_edges(eids)\n",
    "    print('预测路径边数 -> ',len(full_predict))\n",
    "    print('真实路径边数 -> ',len(full_real))\n",
    "    common = longest_common_substring(full_predict,full_real)\n",
    "    print('重叠路径长度 -> ',len(common))\n",
    "    print('重叠率 = 重叠路径长度 / max( 预测路径边数 , 真实路径边数 )  = {:.3f}% '.format(len(common)/max(len(full_predict),len(full_real))*100))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5377c5d0-074d-4778-a3cc-4cea40388795",
   "metadata": {},
   "source": [
    "# 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f54af68-7d73-4b84-954f-2b17c90d8d4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data5.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14452/2410496039.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data5.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data5.txt'"
     ]
    }
   ],
   "source": [
    "# load from file\n",
    "locations=[]\n",
    "\n",
    "\n",
    "file = open(\"data5.txt\",\"r\")\n",
    "while True:\n",
    "    line = file.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    tokens = line.strip().split(' ')\n",
    "    locations.append([float(tokens[0]),float(tokens[1])])\n",
    "file.close()\n",
    "\n",
    "coords = locations\n",
    "\n",
    "predict = map_mapping(transformer, coords)\n",
    "full_predict = gen_full_edges(predict)\n",
    "\n",
    "print(json.dumps(full_predict))\n",
    "print('预测路径边数 -> ',len(full_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3905ec-ad9d-49b3-aa32-6949ad717ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "# define the world map\n",
    "world_map = folium.Map(location=coords[0],zoom_start=13)\n",
    "\n",
    "#画原始轨迹\n",
    "for i in range(1,len(coords)):\n",
    "    points = [coords[i-1], coords[i]]\n",
    "    folium.PolyLine(points, color='red', weight=2).add_to(world_map)\n",
    "    \n",
    "\n",
    "#画真实\n",
    "for i in range(1,len(full_real)):\n",
    "    points = json.loads(edges.loc[full_real[i],'locations'])\n",
    "    folium.PolyLine(points, color='green', weight=2).add_to(world_map)\n",
    "    \n",
    "    \n",
    "#画预测\n",
    "for i in range(1,len(full_predict)):\n",
    "    points = json.loads(edges.loc[int(full_predict[i]),'locations'])\n",
    "    folium.PolyLine(points, color='purple', weight=2).add_to(world_map)\n",
    "    \n",
    "world_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
